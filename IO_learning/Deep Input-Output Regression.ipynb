{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np;\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math;\n",
    "import random;\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt;\n",
    "import pickle\n",
    "import sklearn.preprocessing as preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Input-Output Regression.ipynb\r\n",
      "DeepIO_Regression.py\r\n",
      "DeepIO_Regression.py~\r\n",
      "DeepIO_Regression_GPU0.py\r\n",
      "DeepIO_Regression_GPU0.py~\r\n",
      "DeepIO_Regression_GPU1.py\r\n",
      "DeepIO_Regression_GPU2.py\r\n",
      "DeepIO_Regression_GPU3.py\r\n",
      "DeepIO_Regression_GPU3.py~\r\n",
      "High_variance_genes.csv\r\n",
      "NAND_Titration_IO_data_NAND_Circuit_full.pickle\r\n",
      "NAND_Titration_IO_data_empty_landing_pads_full.pickle\r\n",
      "RNAseq_merged.csv\r\n",
      "all_error_history.pdf\r\n",
      "\u001b[34malt_data\u001b[m\u001b[m\r\n",
      "outputs.pdf\r\n",
      "varied_genes_heatmap.png\r\n"
     ]
    }
   ],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ydata shape:(480, 4110)\n",
      "Udata shape:(480, 2)\n"
     ]
    }
   ],
   "source": [
    "file_obj = open('NAND_Titration_IO_data_empty_landing_pads_full.pickle','rb')\n",
    "#file_obj = open('NAND_Titration_IO_data_MG1655_empty_landing_pads.pickle','rb')\n",
    "#file_obj = open('NAND_Titration_IO_data_MG1655_NAND_Circuit.pickle','rb')\n",
    "allVars = pickle.load(file_obj)\n",
    "Udata_raw = allVars[0]  #Output Data \n",
    "Ydata_raw = allVars[1]  #Input Data\n",
    "print(\"Ydata shape:\" + repr(Ydata_raw.shape));\n",
    "print(\"Udata shape:\" + repr(Udata_raw.shape));\n",
    "\n",
    "Ydata_raw = np.log2(np.asarray(Ydata_raw,dtype=np.float32)+1e-15)\n",
    "\n",
    "Udata_raw = np.log2(np.asarray(Udata_raw,dtype=np.float32)+1e-15)\n",
    "\n",
    "\n",
    "YmmS = preprocessing.StandardScaler();\n",
    "UmmS = preprocessing.Normalizer();\n",
    "Ydata = YmmS.fit_transform(Ydata_raw.T)\n",
    "Udata = UmmS.fit_transform(Udata_raw.T)*-1e1\n",
    "#UmmS.inverse_transform(....)\n",
    "Ydata = Ydata;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.21658956 0.9841908  0.9841908  0.9841908  0.9841908  0.9841908\n",
      "  0.28220227 0.28220227 0.28220227 0.28220227 0.28220227 0.10511551\n",
      "  0.10511551 0.10511551 0.10511551 0.10511551 0.347815   0.347815\n",
      "  0.347815   0.347815   0.347815   0.21658956 0.21658956 0.21658956\n",
      "  0.21658956 0.21658956 0.9841908  0.9841908  0.9841908  0.9841908\n",
      "  0.9841908  0.28220227 0.28220227 0.28220227 0.28220227 0.28220227\n",
      "  0.15097684 0.15097684 0.15097684 0.15097684 0.15097684 0.10511551\n",
      "  0.10511551 0.10511551 0.10511551 0.10511551 0.347815   0.347815\n",
      "  0.347815   0.347815   0.347815   0.21658956 0.21658956 0.21658956\n",
      "  0.21658956 0.21658956 0.9841908  0.9841908  0.9841908  0.9841908\n",
      "  0.9841908  0.28220227 0.28220227 0.28220227 0.28220227 0.28220227\n",
      "  0.15097684 0.15097684 0.15097684 0.15097684 0.15097684 0.10511551\n",
      "  0.10511551 0.10511551 0.10511551 0.10511551 0.347815   0.347815\n",
      "  0.347815   0.347815   0.347815   0.21658956 0.21658956 0.21658956\n",
      "  0.21658956 0.21658956 0.9841908  0.9841908  0.9841908  0.9841908\n",
      "  0.9841908  0.28220227 0.28220227 0.28220227 0.28220227 0.28220227\n",
      "  0.15097684 0.15097684 0.15097684 0.15097684 0.15097684 0.10511551\n",
      "  0.10511551 0.10511551 0.10511551 0.10511551 0.347815   0.347815\n",
      "  0.347815   0.347815   0.347815   0.21658956 0.21658956 0.21658956\n",
      "  0.21658956 0.21658956 0.9841908  0.9841908  0.9841908  0.9841908\n",
      "  0.9841908  0.28220227 0.28220227 0.28220227 0.28220227 0.28220227\n",
      "  0.15097684 0.15097684 0.15097684 0.15097684 0.15097684 0.10511551\n",
      "  0.15097684 0.10511551 0.10511551 0.10511551 0.10511551 0.15097684\n",
      "  0.347815   0.347815   0.347815   0.347815   0.347815   0.15097684\n",
      "  0.15097684 0.21658956 0.21658956 0.21658956 0.21658956 0.21658956\n",
      "  0.15097684 0.15097684 0.9841908  0.9841908  0.9841908  0.9841908\n",
      "  0.28220227 0.28220227 0.28220227 0.28220227 0.15097684 0.15097684\n",
      "  0.15097684 0.15097684 0.10511551 0.10511551 0.10511551 0.10511551\n",
      "  0.10511551 0.347815   0.347815   0.347815   0.347815   0.347815\n",
      "  0.10511551 0.10511551 0.21658956 0.21658956 0.21658956 0.21658956\n",
      "  0.10511551 0.10511551 0.9841908  0.9841908  0.9841908  0.9841908\n",
      "  0.28220227 0.28220227 0.28220227 0.28220227 0.28220227 0.15097684\n",
      "  0.15097684 0.15097684 0.15097684 0.10511551 0.10511551 0.10511551\n",
      "  0.10511551 0.347815   0.347815   0.347815   0.347815   0.347815\n",
      "  0.347815   0.347815   0.21658956 0.347815   0.21658956 0.21658956\n",
      "  0.21658956 0.347815   0.347815   0.21658956 0.21658956 0.21658956\n",
      "  0.21658956 0.21658956 0.9841908  0.9841908  0.9841908  0.15097684\n",
      "  0.15097684 0.15097684 0.15097684 0.15097684 0.9841908  0.9841908\n",
      "  0.9841908  0.9841908  0.9841908  0.9841908  0.9841908  0.28220227\n",
      "  0.28220227 0.28220227 0.28220227 0.28220227 0.15097684 0.15097684\n",
      "  0.15097684 0.15097684 0.15097684 0.10511551 0.10511551 0.10511551\n",
      "  0.10511551 0.10511551 0.347815   0.347815   0.347815   0.347815\n",
      "  0.347815   0.21658956 0.21658956 0.21658956 0.21658956 0.21658956\n",
      "  0.9841908  0.9841908  0.9841908  0.9841908  0.9841908  0.28220227\n",
      "  0.28220227 0.28220227 0.28220227 0.28220227 0.15097684 0.15097684\n",
      "  0.15097684 0.15097684 0.15097684 0.10511551 0.10511551 0.10511551\n",
      "  0.10511551 0.10511551 0.347815   0.347815   0.347815   0.347815\n",
      "  0.347815   0.21658956 0.21658956 0.21658956 0.21658956 0.21658956\n",
      "  0.9841908  0.9841908  0.9841908  0.9841908  0.9841908  0.28220227\n",
      "  0.28220227 0.28220227 0.28220227 0.28220227 0.15097684 0.15097684\n",
      "  0.15097684 0.15097684 0.15097684 0.10511551 0.10511551 0.10511551\n",
      "  0.10511551 0.10511551 0.347815   0.347815   0.347815   0.347815\n",
      "  0.347815   0.21658956 0.21658956 0.21658956 0.21658956 0.9841908\n",
      "  0.9841908  0.9841908  0.9841908  0.9841908  0.28220227 0.28220227\n",
      "  0.28220227 0.28220227 0.28220227 0.15097684 0.15097684 0.15097684\n",
      "  0.15097684 0.15097684 0.10511551 0.10511551 0.10511551 0.10511551\n",
      "  0.10511551 0.347815   0.347815   0.347815   0.347815   0.347815\n",
      "  0.21658956 0.21658956 0.21658956 0.21658956 0.21658956 0.28220227\n",
      "  0.28220227 0.15097684 0.28220227 0.347815   0.28220227 0.21658956\n",
      "  0.10511551 0.21658956 0.15097684 0.9841908  0.9841908  0.9841908\n",
      "  0.9841908  0.9841908  0.9841908  0.28220227 0.28220227 0.28220227\n",
      "  0.28220227 0.28220227 0.15097684 0.15097684 0.15097684 0.15097684\n",
      "  0.15097684 0.10511551 0.10511551 0.10511551 0.10511551 0.10511551\n",
      "  0.347815   0.347815   0.347815   0.347815   0.347815   0.21658956\n",
      "  0.21658956 0.21658956 0.21658956 0.21658956 0.9841908  0.9841908\n",
      "  0.9841908  0.9841908  0.9841908  0.28220227 0.28220227 0.28220227\n",
      "  0.28220227 0.28220227 0.15097684 0.15097684 0.15097684 0.15097684\n",
      "  0.10511551 0.10511551 0.10511551 0.10511551 0.10511551 0.347815\n",
      "  0.347815   0.347815   0.347815   0.347815   0.21658956 0.21658956\n",
      "  0.21658956 0.21658956 0.21658956 0.9841908  0.9841908  0.9841908\n",
      "  0.9841908  0.9841908  0.28220227 0.28220227 0.28220227 0.28220227\n",
      "  0.15097684 0.15097684 0.15097684 0.15097684 0.15097684 0.10511551\n",
      "  0.10511551 0.10511551 0.10511551 0.10511551 0.347815   0.347815\n",
      "  0.347815   0.347815   0.21658956 0.21658956 0.21658956 0.21658956\n",
      "  0.21658956 0.9841908  0.9841908  0.9841908  0.9841908  0.9841908\n",
      "  0.28220227 0.28220227 0.28220227 0.28220227 0.28220227 0.15097684\n",
      "  0.15097684 0.15097684 0.15097684 0.15097684 0.10511551 0.10511551\n",
      "  0.10511551 0.10511551 0.10511551 0.347815   0.347815   0.347815\n",
      "  0.347815   0.347815   0.21658956 0.21658956 0.21658956 0.21658956\n",
      "  0.21658956 0.28220227 0.9841908  0.28220227 0.28220227 0.10511551]\n",
      " [0.3686294  0.83753276 0.3686294  0.31279388 0.25695837 0.20112285\n",
      "  0.83753276 0.3686294  0.31279388 0.25695837 0.20112285 0.83753276\n",
      "  0.3686294  0.31279388 0.25695837 0.20112285 0.83753276 0.3686294\n",
      "  0.31279388 0.25695837 0.20112285 0.83753276 0.3686294  0.31279388\n",
      "  0.25695837 0.20112285 0.83753276 0.3686294  0.31279388 0.25695837\n",
      "  0.20112285 0.83753276 0.3686294  0.31279388 0.25695837 0.20112285\n",
      "  0.83753276 0.3686294  0.31279388 0.25695837 0.20112285 0.83753276\n",
      "  0.3686294  0.31279388 0.25695837 0.20112285 0.83753276 0.3686294\n",
      "  0.31279388 0.25695837 0.20112285 0.83753276 0.3686294  0.31279388\n",
      "  0.25695837 0.20112285 0.83753276 0.3686294  0.31279388 0.25695837\n",
      "  0.20112285 0.83753276 0.3686294  0.31279388 0.25695837 0.20112285\n",
      "  0.83753276 0.3686294  0.31279388 0.25695837 0.20112285 0.83753276\n",
      "  0.3686294  0.31279388 0.25695837 0.20112285 0.83753276 0.3686294\n",
      "  0.31279388 0.25695837 0.20112285 0.83753276 0.3686294  0.31279388\n",
      "  0.25695837 0.20112285 0.83753276 0.3686294  0.31279388 0.25695837\n",
      "  0.20112285 0.83753276 0.3686294  0.31279388 0.25695837 0.20112285\n",
      "  0.83753276 0.3686294  0.31279388 0.25695837 0.20112285 0.83753276\n",
      "  0.3686294  0.31279388 0.25695837 0.20112285 0.83753276 0.3686294\n",
      "  0.31279388 0.25695837 0.20112285 0.83753276 0.3686294  0.31279388\n",
      "  0.25695837 0.20112285 0.83753276 0.3686294  0.31279388 0.25695837\n",
      "  0.20112285 0.83753276 0.3686294  0.31279388 0.25695837 0.20112285\n",
      "  0.83753276 0.3686294  0.31279388 0.25695837 0.20112285 0.83753276\n",
      "  0.83753276 0.3686294  0.31279388 0.25695837 0.20112285 0.83753276\n",
      "  0.83753276 0.3686294  0.31279388 0.25695837 0.20112285 0.3686294\n",
      "  0.31279388 0.83753276 0.3686294  0.31279388 0.25695837 0.20112285\n",
      "  0.25695837 0.20112285 0.3686294  0.31279388 0.25695837 0.20112285\n",
      "  0.3686294  0.31279388 0.25695837 0.20112285 0.3686294  0.31279388\n",
      "  0.25695837 0.20112285 0.3686294  0.31279388 0.25695837 0.20112285\n",
      "  0.83753276 0.83753276 0.3686294  0.31279388 0.25695837 0.20112285\n",
      "  0.3686294  0.31279388 0.3686294  0.31279388 0.25695837 0.20112285\n",
      "  0.25695837 0.20112285 0.3686294  0.31279388 0.25695837 0.20112285\n",
      "  0.83753276 0.3686294  0.31279388 0.25695837 0.20112285 0.3686294\n",
      "  0.31279388 0.25695837 0.20112285 0.83753276 0.31279388 0.25695837\n",
      "  0.20112285 0.83753276 0.83753276 0.3686294  0.31279388 0.25695837\n",
      "  0.20112285 0.3686294  0.83753276 0.31279388 0.31279388 0.25695837\n",
      "  0.20112285 0.25695837 0.20112285 0.83753276 0.3686294  0.31279388\n",
      "  0.25695837 0.20112285 0.83753276 0.3686294  0.31279388 0.83753276\n",
      "  0.3686294  0.31279388 0.25695837 0.20112285 0.25695837 0.20112285\n",
      "  0.83753276 0.3686294  0.31279388 0.25695837 0.20112285 0.83753276\n",
      "  0.3686294  0.31279388 0.25695837 0.20112285 0.83753276 0.3686294\n",
      "  0.31279388 0.25695837 0.20112285 0.83753276 0.3686294  0.31279388\n",
      "  0.25695837 0.20112285 0.83753276 0.3686294  0.31279388 0.25695837\n",
      "  0.20112285 0.83753276 0.3686294  0.31279388 0.25695837 0.20112285\n",
      "  0.83753276 0.3686294  0.31279388 0.25695837 0.20112285 0.83753276\n",
      "  0.3686294  0.31279388 0.25695837 0.20112285 0.83753276 0.3686294\n",
      "  0.31279388 0.25695837 0.20112285 0.83753276 0.3686294  0.31279388\n",
      "  0.25695837 0.20112285 0.83753276 0.3686294  0.31279388 0.25695837\n",
      "  0.20112285 0.83753276 0.3686294  0.31279388 0.25695837 0.20112285\n",
      "  0.83753276 0.3686294  0.31279388 0.25695837 0.20112285 0.83753276\n",
      "  0.3686294  0.31279388 0.25695837 0.20112285 0.83753276 0.3686294\n",
      "  0.31279388 0.25695837 0.20112285 0.83753276 0.3686294  0.31279388\n",
      "  0.25695837 0.20112285 0.83753276 0.3686294  0.31279388 0.25695837\n",
      "  0.20112285 0.83753276 0.3686294  0.31279388 0.25695837 0.83753276\n",
      "  0.3686294  0.31279388 0.25695837 0.20112285 0.83753276 0.3686294\n",
      "  0.31279388 0.25695837 0.20112285 0.83753276 0.3686294  0.31279388\n",
      "  0.25695837 0.20112285 0.83753276 0.3686294  0.31279388 0.25695837\n",
      "  0.20112285 0.83753276 0.3686294  0.31279388 0.25695837 0.20112285\n",
      "  0.83753276 0.3686294  0.31279388 0.25695837 0.20112285 0.3686294\n",
      "  0.20112285 0.25695837 0.25695837 0.20112285 0.83753276 0.20112285\n",
      "  0.83753276 0.83753276 0.83753276 0.83753276 0.83753276 0.3686294\n",
      "  0.31279388 0.25695837 0.20112285 0.83753276 0.3686294  0.31279388\n",
      "  0.25695837 0.20112285 0.83753276 0.3686294  0.31279388 0.25695837\n",
      "  0.20112285 0.83753276 0.3686294  0.31279388 0.25695837 0.20112285\n",
      "  0.83753276 0.3686294  0.31279388 0.25695837 0.20112285 0.83753276\n",
      "  0.3686294  0.31279388 0.25695837 0.20112285 0.83753276 0.3686294\n",
      "  0.31279388 0.25695837 0.20112285 0.83753276 0.3686294  0.31279388\n",
      "  0.25695837 0.20112285 0.83753276 0.3686294  0.31279388 0.20112285\n",
      "  0.83753276 0.3686294  0.31279388 0.25695837 0.20112285 0.83753276\n",
      "  0.3686294  0.31279388 0.25695837 0.20112285 0.83753276 0.3686294\n",
      "  0.31279388 0.25695837 0.20112285 0.83753276 0.3686294  0.31279388\n",
      "  0.25695837 0.20112285 0.83753276 0.3686294  0.31279388 0.20112285\n",
      "  0.83753276 0.3686294  0.31279388 0.25695837 0.20112285 0.83753276\n",
      "  0.3686294  0.31279388 0.25695837 0.20112285 0.83753276 0.3686294\n",
      "  0.31279388 0.25695837 0.83753276 0.3686294  0.31279388 0.25695837\n",
      "  0.20112285 0.83753276 0.3686294  0.31279388 0.25695837 0.20112285\n",
      "  0.83753276 0.3686294  0.31279388 0.25695837 0.20112285 0.83753276\n",
      "  0.3686294  0.31279388 0.25695837 0.20112285 0.83753276 0.3686294\n",
      "  0.31279388 0.25695837 0.20112285 0.83753276 0.3686294  0.31279388\n",
      "  0.25695837 0.20112285 0.83753276 0.3686294  0.31279388 0.25695837\n",
      "  0.20112285 0.83753276 0.83753276 0.31279388 0.25695837 0.3686294 ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns \n",
    "sns.heatmap(Udata)\n",
    "print(Udata[0:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 480)\n",
      "(4110, 480)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.44757086"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(Udata.shape)\n",
    "print(Ydata.shape)\n",
    "K = np.dot(Ydata,np.linalg.pinv(Udata))\n",
    "#K = np.dot(np.linalg.pinv(Udata),Ydata)\n",
    "#print(K.shape)\n",
    "np.linalg.norm(Ydata - np.dot(K,Udata),ord=2)/np.linalg.norm(Ydata,ord=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "# pca = PCA(n_components=50)\n",
    "# pca.fit(Ydata)  \n",
    "# PCA(copy=True, iterated_power='auto', n_components=2, random_state=None,\n",
    "#   svd_solver='auto', tol=0.0, whiten=False)\n",
    "# print(pca.explained_variance_ratio_)  \n",
    "# print(pca.singular_values_)  \n",
    "# Ydata = pca.transform(Ydata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expose_deep_basis(z_list,num_bas_obs,deep_dict_size,iter_num,u):\n",
    "    basis_hooks = z_list[-1]; #[-1] is y  = K *\\phi; -2 is \\phi(yk)\n",
    "    x_range = np.arange(-10.0,10.0,0.1);\n",
    "\n",
    "    for i in range(0,num_bas_obs):\n",
    "        plt.close();\n",
    "        scan_injection = np.zeros((len(x_range),num_bas_obs));\n",
    "        scan_injection[:,i]= np.transpose(x_range);\n",
    "        phi_j = basis_hooks.eval(feed_dict={u:scan_injection});\n",
    "        fig_hand = plt.gcf()\n",
    "        plt.plot(x_range,phi_j,'.-',label='\\phi_i(y)');\n",
    "        #plt.ylim([-2.0,2.0]);\n",
    "        fig = plt.gcf();\n",
    "        plt.savefig('deep_basis_images/phi_with_u' + repr(i) + '_iternum_' + repr(iter_num) + '.jpg');\n",
    "\n",
    "    return fig_hand;        \n",
    "\n",
    "def xavier_init(n_inputs, n_outputs, uniform=True):\n",
    "    \"\"\"Set the parameter initialization using the method described.\n",
    "    This method is designed to keep the scale of the gradients roughly the same\n",
    "    in all layers.\n",
    "    Xavier Glorot and Yoshua Bengio (2010):\n",
    "       Understanding the difficulty of training deep feedforward neural\n",
    "       networks. International conference on artificial intelligence and\n",
    "       statistics.\n",
    "    Args:\n",
    "    n_inputs: The number of input nodes into each output.\n",
    "    n_outputs: The number of output nodes for each input.\n",
    "    uniform: If true use a uniform distribution, otherwise use a normal.\n",
    "    Returns:\n",
    "    An initializer.\n",
    "    \"\"\"\n",
    "    if uniform:\n",
    "        # 6 was used in the paper.\n",
    "        init_range = math.sqrt(6.0 / (n_inputs + n_outputs))\n",
    "        return tf.random_uniform_initializer(-init_range, init_range)\n",
    "    else:\n",
    "        # 3 gives us approximately the same limits as above since this repicks\n",
    "        # values greater than 2 standard deviations from the mean.\n",
    "        stddev = math.sqrt(3.0 / (n_inputs + n_outputs))\n",
    "        return tf.truncated_normal_initializer(stddev=stddev)\n",
    "\n",
    "def weight_variable(shape):\n",
    "    std_dev = math.sqrt(3.0 /(shape[0] + shape[1]))\n",
    "    return tf.Variable(tf.truncated_normal(shape, mean=0.0,stddev=std_dev,dtype=tf.float32));\n",
    "  \n",
    "def bias_variable(shape):\n",
    "    std_dev = math.sqrt(3.0 / shape[0])\n",
    "    return tf.Variable(tf.truncated_normal(shape, mean=0.0,stddev=std_dev,dtype=tf.float32));\n",
    "\n",
    "\n",
    "def network_assemble(input_var,W_list,b_list,keep_prob=1.0,activation_flag=1,res_net=0):\n",
    "    n_depth = len(W_list);\n",
    "    print(\"n_depth: \" + repr(n_depth));\n",
    "    z_temp_list = [];\n",
    "    \n",
    "    for k in range(0,n_depth):\n",
    "        \n",
    "        if (k==0):\n",
    "            W1 = W_list[0];\n",
    "            b1 = b_list[0];\n",
    "            if activation_flag==1:# RELU\n",
    "                z1 = tf.nn.dropout(tf.nn.relu(tf.matmul(input_var,W1)+b1),keep_prob);\n",
    "            if activation_flag==2: #ELU \n",
    "                z1 = tf.nn.dropout(tf.nn.elu(tf.matmul(input_var,W1)+b1),keep_prob);\n",
    "            if activation_flag==3: # tanh\n",
    "                z1 = tf.nn.dropout(tf.nn.tanh(tf.matmul(input_var,W1)+b1),keep_prob);\n",
    "\n",
    "            z_temp_list.append(z1);\n",
    "            \n",
    "\n",
    "        if not (k==0) and k < (n_depth-1):\n",
    "            \n",
    "            prev_layer_output = tf.matmul(z_temp_list[k-1],W_list[k])+b_list[k]\n",
    "\n",
    "            if res_net and k==(n_depth-2):\n",
    "                prev_layer_output += tf.matmul(u,W1)+b1 #  this expression is not compatible for variable width nets (where each layer has a different width at inialization - okay with regularization and dropout afterwards though)\n",
    "\n",
    "            if activation_flag==1:\n",
    "                z_temp_list.append(tf.nn.dropout(tf.nn.relu(prev_layer_output),keep_prob));\n",
    "            if activation_flag==2:\n",
    "                z_temp_list.append(tf.nn.dropout(tf.nn.elu(prev_layer_output),keep_prob));\n",
    "            if activation_flag==3:\n",
    "                z_temp_list.append(tf.nn.dropout(tf.nn.tanh(prev_layer_output),keep_prob));\n",
    "\n",
    "                \n",
    "        if not (k==0) and k == (n_depth-1):\n",
    "            prev_layer_output = tf.matmul(z_temp_list[k-1],W_list[k])+b_list[k];\n",
    "            z_temp_list.append(prev_layer_output);\n",
    "\n",
    "        \n",
    "    if debug_splash:\n",
    "        print(\"[DEBUG] z_list\" + repr(z_list[-1]));\n",
    "        \n",
    "    #y_out = tf.concat([z_list[-1],u],axis=1); # last element of activation output list is the actual NN output\n",
    "    y_out = z_temp_list[-1];\n",
    "    \n",
    "    result = sess.run(tf.global_variables_initializer())\n",
    "    return y_out,z_temp_list;\n",
    "\n",
    "\n",
    "def initialize_Wblist(n_u,hv_list):\n",
    "    W_list = [];\n",
    "    b_list = [];\n",
    "    n_depth = len(hv_list);\n",
    "    print(\"Length of hv_list: \" + repr(n_depth))\n",
    "    #hv_list[n_depth-1] = n_y;\n",
    "    for k in range(0,n_depth):\n",
    "        \n",
    "        if k==0:\n",
    "            W1 = weight_variable([n_u,hv_list[k]]);\n",
    "            b1 = bias_variable([hv_list[k]]);\n",
    "            W_list.append(W1);\n",
    "            b_list.append(b1);\n",
    "        else:\n",
    "            W_list.append(weight_variable([hv_list[k-1],hv_list[k]]));\n",
    "            b_list.append(bias_variable([hv_list[k]]));\n",
    "    result = sess.run(tf.global_variables_initializer())\n",
    "    return W_list,b_list;\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_net(y_all_training,y_feed,u_all_training,u_feed,obj_func,optimizer,u_control_all_training=None,valid_error_thres=1e-2,test_error_thres=1e-2,max_iters=100000,step_size_val=0.01,batchsize=10):\n",
    "\n",
    "  iter = 0;\n",
    "  samplerate = 5000;\n",
    "  good_start = 1;\n",
    "  valid_error = 100.0;\n",
    "  test_error = 100.0;\n",
    "  training_error_history_nocovar = [];\n",
    "  validation_error_history_nocovar = [];\n",
    "  test_error_history_nocovar = [];\n",
    "\n",
    "  training_error_history_withcovar = [];\n",
    "  validation_error_history_withcovar = [];\n",
    "  test_error_history_withcovar = [];\n",
    "\n",
    "\n",
    "  while (((test_error>test_error_thres) or (valid_error > valid_error_thres)) and iter < max_iters):\n",
    "    iter+=1;\n",
    "    \n",
    "    all_ind = set(np.arange(0,len(u_all_training)));\n",
    "    select_ind = np.random.randint(0,len(u_all_training),size=batchsize);\n",
    "    valid_ind = list(all_ind -set(select_ind))[0:batchsize];\n",
    "    select_ind_test = list(all_ind - set(valid_ind) - set(select_ind))[0:batchsize];\n",
    "\n",
    "    \n",
    "    u_batch =[];\n",
    "    u_control_batch = [];\n",
    "    y_batch = [];\n",
    "    u_valid = [];\n",
    "    u_control_valid = [];\n",
    "    y_valid = [];\n",
    "    u_test_train = [];\n",
    "    u_control_train = [];\n",
    "    y_test_train= [];\n",
    "    u_control_test_train = [];\n",
    "    \n",
    "    for j in range(0,len(select_ind)):\n",
    "      u_batch.append(u_all_training[select_ind[j]]);  \n",
    "#      y_batch = embed_feed.eval(feed_dict={u_feed:u_batch});\n",
    "      y_batch.append(y_all_training[select_ind[j]]);\n",
    "          \n",
    "    for k in range(0,len(valid_ind)):\n",
    "      u_valid.append(u_all_training[valid_ind[k]]);\n",
    "      y_valid.append(y_all_training[valid_ind[k]]);\n",
    "#      y_valid = embed_feed.eval(feed_dict={u_feed:u_valid});\n",
    "\n",
    "\n",
    "    for k in range(0,len(select_ind_test)):\n",
    "      u_test_train.append(u_all_training[select_ind_test[k]]);\n",
    "      y_test_train.append(y_all_training[select_ind_test[k]]);  \n",
    "#    y_test_train = embed_feed.eval(feed_dict={u_feed:u_test_train});\n",
    "    u_batch = np.asarray(u_batch);\n",
    "    y_batch = np.asarray(y_batch);\n",
    "    #print(\"u_feed:\" + repr(u_feed));\n",
    "    #print(\"y_feed:\" + repr(y_feed));\n",
    "    optimizer.run(feed_dict={u_feed:u_batch,y_feed:y_batch,step_size:step_size_val});\n",
    "    valid_error = obj_func.eval(feed_dict={u_feed:u_valid,y_feed:y_valid});\n",
    "    test_error = obj_func.eval(feed_dict={u_feed:u_test_train,y_feed:y_test_train});\n",
    "\n",
    "    \n",
    "    if iter%samplerate==0:\n",
    "      training_error_history_nocovar.append(obj_func.eval(feed_dict={u_feed:u_batch,y_feed:y_batch}));\n",
    "      validation_error_history_nocovar.append(obj_func.eval(feed_dict={u_feed:u_valid,y_feed:y_valid}));\n",
    "      test_error_history_nocovar.append(obj_func.eval(feed_dict={u_feed:u_test_train,y_feed:y_test_train}));\n",
    "\n",
    "  \n",
    "      if (iter%10==0) or (iter==1):\n",
    "        #plt.close();                  \n",
    "        print (\"step %d , validation error %g\"%(iter, obj_func.eval(feed_dict={u_feed:u_valid,y_feed:y_valid})));\n",
    "        print (\"step %d , test error %g\"%(iter, obj_func.eval(feed_dict={u_feed:u_test_train,y_feed:y_test_train})));\n",
    "        #print(\"Reconstruction Loss: \" + repr(this_vae_loss.eval(feed_dict={this_u:this_corpus_vec})))\n",
    "#        this_corpus_embed = embed_feed.eval(feed_dict={u_feed:})\n",
    "        #print(\"Embedding Loss: \" + repr(this_embed_loss.eval(feed_dict={this_u:this_corpus_vec})) )\n",
    "    \n",
    "#    if ((iter>20000) and iter%10) :#\n",
    "#\n",
    "#      valid_gradient = np.gradient(np.asarray(validation_error_history_nocovar[iter/samplerate*7/10:]));\n",
    "#      mu_gradient = np.mean(valid_gradient);\n",
    "#\n",
    "#      if ((iter <1000) and (mu_gradient >= 5e-1)): # eventually update this to be 1/10th the mean of batch data, or mean of all data handed as input param to func\n",
    "#        good_start = 0; # if after 10,000 iterations validation error is still above 1e0, initialization was poor.\n",
    "#        print(\"Terminating model refinement loop with gradient:\") + repr(mu_gradient) + \", validation error after \" + repr(iter) + \" epochs:  \" + repr(valid_error);\n",
    "#        iter = max_iters; # terminate while loop and return histories\n",
    "\n",
    "  all_histories = [training_error_history_nocovar, validation_error_history_nocovar,test_error_history_nocovar];\n",
    "  \n",
    "  plt.close();\n",
    "  x = np.arange(0,len(validation_error_history_nocovar),1);\n",
    "  plt.plot(x,training_error_history_nocovar,label='train. err.');\n",
    "  plt.plot(x,validation_error_history_nocovar,label='valid. err.');\n",
    "  plt.plot(x,test_error_history_nocovar,label='test err.');\n",
    "  #plt.gca().set_yscale('log');\n",
    "  plt.savefig('all_error_history.pdf');\n",
    "  \n",
    "  plt.close();\n",
    "  return all_histories,good_start;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def vae_loss(y_model,y_true):\n",
    "        return tf.norm(y_true - y_model,axis=[0,1],ord='fro')/tf.norm(y_true,axis=[0,1],ord='fro');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ydata = Ydata.T;\n",
    "Udata = Udata.T;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim_parameter = 2; \n",
    "#label_dim = 1; \n",
    "intermediate_dim = 30\n",
    "output_dim = Ydata.shape[1];\n",
    "batch_size_parameter=200;#4000 for howard's e. coli dataset\n",
    "debug_splash = 0;\n",
    "this_step_size_val = 0.25;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/client/session.py:1702: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of hv_list: 7\n",
      "n_depth: 7\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-b55af68b4c65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     train_net(Ydata,this_y_true,Udata,this_u,this_io_loss,this_optim,\n\u001b[0;32m---> 23\u001b[0;31m               batchsize = batch_size_parameter,step_size_val = this_step_size_val,max_iters=5e4)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-26-7534dfe3bc13>\u001b[0m in \u001b[0;36mtrain_net\u001b[0;34m(y_all_training, y_feed, u_all_training, u_feed, obj_func, optimizer, u_control_all_training, valid_error_thres, test_error_thres, max_iters, step_size_val, batchsize)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mu_feed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mu_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_feed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0my_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstep_size_val\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mvalid_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mu_feed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mu_valid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_feed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0my_valid\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0mtest_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mu_feed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mu_test_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_feed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0my_test_train\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m     \"\"\"\n\u001b[0;32m--> 695\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   5179\u001b[0m                        \u001b[0;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5180\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 5181\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hidden_vars_list = [input_dim_parameter] + [intermediate_dim]*3 + [output_dim];\n",
    "\n",
    "this_u = tf.placeholder(tf.float32, shape=[None,input_dim_parameter],name=\"InputInducers\");\n",
    "#for d in ['/device:cpu:0']:#, '/device:CPU:3']:\n",
    "\n",
    "    #with tf.device(d):\n",
    "with tf.device('/cpu:0'):\n",
    "    this_W_list,this_b_list = initialize_Wblist(input_dim_parameter,hidden_vars_list);\n",
    "    this_y_out,all_layers = network_assemble(this_u,this_W_list,this_b_list,keep_prob=1.0,\n",
    "                                             activation_flag=2,res_net=0)\n",
    "\n",
    "    this_y_true = tf.placeholder(tf.float32,shape=[None,output_dim],name=\"Groundtruth_Transcriptome\")    \n",
    "    this_output_layer = all_layers[-3]\n",
    "\n",
    "    result = sess.run(tf.global_variables_initializer())\n",
    "    this_io_loss = vae_loss(this_y_out,this_y_true)\n",
    "    this_optim = tf.train.AdagradOptimizer(learning_rate=this_step_size_val).minimize(this_io_loss)\n",
    "    step_size = tf.placeholder(tf.float32,shape=[],name=\"StepSizePlaceholder\");\n",
    "    result = sess.run(tf.global_variables_initializer())\n",
    "    #this_embed_loss = embed_loss(this_u,this_embedding);\n",
    "\n",
    "    train_net(Ydata,this_y_true,Udata,this_u,this_io_loss,this_optim,\n",
    "              batchsize = batch_size_parameter,step_size_val = this_step_size_val,max_iters=5e4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ydata = np.log10(Ydata+1e-15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YT*U*(U^T*U)^{-1} = G "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = np.matmul(Ydata.T,np.matmul(Udata,np.linalg.inv(np.matmul(Udata.T,Udata )) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U_test = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "output = np.matmul(G,U_test.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yout = YmmS.inverse_transform(output.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.cluster as cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yclust = cluster.AgglomerativeClustering(n_clusters=10).fit_predict(Yout.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newOrder = [[i,e] for i,e in enumerate(Yclust)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nS = np.array(newOrder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nS.sort(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster import hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dend = shc.dendrogram(shc.linkage(data_scaled, method='ward'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dend = hierarchy.dendrogram(hierarchy.linkage(Yout.T,method='ward'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yout.T[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yplot = Yout.T\n",
    "Yplot[Yplot < 0] = 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dfM = pd.read_csv('RNAseq_merged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geneNames = dfM.columns[7:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfG = pd.DataFrame(Yplot,index=geneNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfG.loc[['Sensor_LacI','Sensor_AraC','Circuit_PhlF','Circuit_IcaR','Actuator_YFP']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,20))\n",
    "sns.heatmap(np.log10(Yplot),cmap='viridis')\n",
    "\n",
    "plt.savefig('outputs.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yout.T[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "this_xlabels = ['arabinose','iptg']\n",
    "#this_ylabels = ['gene'+repr(ind) for ind in range(0,4110)]\n",
    "sns.set(font_scale=1.4)\n",
    "#hm=sns.heatmap(G,xticklabels=this_xlabels,#yticklabels=this_ylabels,cmap='RdYlGn',annot=False)\n",
    "hm=sns.heatmap((np.log10(G)+1e-15),xticklabels=this_xlabels,cmap='RdYlGn',annot=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
